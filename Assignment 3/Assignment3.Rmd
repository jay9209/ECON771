---
title: "Assignment3"
author: "Jung Jae Kim"
output:
  html_document:
    df_print: paged
always_allow_html: yes
extra_dependencies:
  amsmath: null
---

```{r setup, include=FALSE, cache=TRUE, tidy=TRUE, echo=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, janitor, reshape2, here, haven, xtable, rdrobust, rddensity, modelsummary, kableExtra)
knitr::opts_chunk$set(echo = TRUE)
```


```{r import-data, include=FALSE, warning=FALSE}
df <- read_dta('Assignment 3/data/Data_main.dta')
df_subsidy <- read_dta('Assignment 3/data/Data_subsidyinfo.dta')

df_subsidy <- df_subsidy %>%
  pivot_longer(cols = c('s2006','s2007','s2008','s2009','s2010'),
               names_to = 'year',
               values_to = 'subsidy') %>%
  mutate(year = parse_number(year))

df <- df %>% left_join(df_subsidy, by=c('PDPregion','year'))

# define variables that are repeatedly used in analysis
df <- df %>% 
  group_by(state, year) %>%
  mutate(stateYrEnroll = sum(enrollment, na.rm=T)) %>%
  ungroup() %>%
  mutate(LIS = premium - subsidy,
         share = enrollment/stateYrEnroll,
         log_share = log(share))
```


Questions

1. Recreate the table of descriptive statistics (Table 1) from @ericson2014.

```{r Q1, tidy=TRUE, echo=TRUE, cache=TRUE, comment=NA, warning=FALSE,include=FALSE}
df_q1 <- df %>% 
  group_by(uniqueID) %>%
  mutate(cohort = min(year)) %>%
  ungroup() %>%
  mutate(enhanced = ifelse(benefit=='E',1,0)) %>%
  group_by(orgParentCode) %>%
  mutate(entry_year = min(year)) %>%
  mutate(already = ifelse(year==entry_year,0,1)) %>%
  ungroup() %>%
  group_by(orgParentCode, state) %>%
  mutate(entry_year_state = min(year)) %>%
  mutate(already_state = ifelse(year==entry_year,0,1)) %>%
  ungroup()

table1 <- df_q1 %>%
  filter(year==cohort) %>% 
  group_by(year) %>%
  summarise('Mean monthly premium' = as.integer(mean(premium)),
            'sd_premium' = as.integer(sd(premium)),
            'Mean deductible' = as.integer(mean(deductible)),
            'sd_deductible' = as.integer(sd(deductible)),
            'Fraction enhanced benefit' = round(mean(enhanced),2),
            '...in the U.S.' = round(mean(already),2),
            '...in the same state' = round(mean(already_state),2),
            'N Unique Firms' = n_distinct(orgParentCode),
            'N Plans' = n()) %>%
  t() %>%
  row_to_names(row_number=1)
```
```{r Q1-display, tidy=TRUE, echo=FALSE, cache=TRUE, comment=NA, warning=FALSE}
table1 %>% kbl() %>% kable_styling(position = "center",full_width=TRUE)
```



2. Recreate Figure 3 from @ericson2014. 
```{r Q2, tidy=TRUE, echo=TRUE, cache=TRUE, comment=NA, warning=FALSE,include=FALSE}
df_q2 <- df %>%
  filter(benefit == 'B',
         year==2006,
         LIS <= 10, LIS >=-10)

rd_linear <- rdplot(y = df_q2$log_share,
                    x = df_q2$LIS,
                    h = 4, p=1, hide=T)
linear <- as_tibble(rd_linear$vars_poly)

rd_quartic <- rdplot(y = df_q2$log_share,
                     x = df_q2$LIS,
                     c = 0, p = 4, h=10, n=20, hide=T)
bin.avg <- as_tibble(rd_quartic$vars_bins)
quartic <- as_tibble(rd_quartic$vars_poly)

figure1 <- bin.avg %>%
  ggplot() +
  geom_point(aes(x=rdplot_mean_x,y=rdplot_mean_y)) + theme_bw() +
  geom_line(mapping=aes(x=rdplot_x,y=rdplot_y),data=linear,linetype='dashed') +
  geom_line(mapping=aes(x=rdplot_x,y=rdplot_y),data=quartic) +
  xlab("Monthly Premium - LIS Subsidy, 2006") +
  ylab("Log Enrollment Share, 2006")
```

```{r Q2-display, tidy=TRUE, echo=FALSE, cache=TRUE, comment=NA, warning=FALSE}
figure1
```

3. @calonico2015 discuss the appropriate partition size for binned scatterplots such as that in Figure 3 of Ericson (2014). More formally, denote by $\mathcal{P}_{-,n} = \{ P_{-,j} : j=1, 2, ... J_{-, n} \}$ and $\mathcal{P}_{+,n} = \{ P_{+,j} : j=1, 2, ... J_{+, n} \}$ the partitions of the support of the running variable $x_{i}$ on the left and right (respectively) of the cutoff, $\bar{x}$. $P_{-, j}$ and $P_{+, n}$ denote the actual supports for each $j$ partition of size $J_{-,n}$ and $J_{+,n}$, such that $[x_{l}, \bar{x}) = \bigcup_{j=1}^{J_{-,n}} P_{-, j}$ and $(\bar{x}, x_{u}] = \bigcup_{j=1}^{J_{+,n}} P_{+, j}$. Individual bins are denoted by $p_{-,j}$ and $p_{+,j}$. With this notation in hand, we can write the partitions $J_{-,n}$ and $J_{+,n}$ with equally-spaced bins as $$p_{-,j}=x_{l} + j \times \frac{\bar{x} - x_{l}}{J_{-,n}},$$ and $$p_{+,j} = \bar{x} + j \times \frac{x_{u} - \bar{x}}{J_{+,n}}.$$ Recreate Figure 3 from Ericson (2014) using $J_{-,n}=J_{+,n}=10$ and $J_{-,n}=J_{+,n}=30$. Discuss your results and compare them to your figure in Part 2.

```{r Q3, tidy=TRUE, echo=FALSE, cache=TRUE, comment=NA, warning=FALSE,include=FALSE}
J = 10
df_q3_10 <- df %>%
  filter(benefit == 'B',
         year==2006,
         LIS <= 10, LIS >=-10)

rd_linear <- rdplot(y = df_q3_10$log_share,
                    x = df_q3_10$LIS,
                    h = 4, p=1, hide=T)

linear <- as_tibble(rd_linear$vars_poly)

rd_quartic <- rdplot(y = df_q3_10$log_share,
                     x = df_q3_10$LIS,
                     c = 0, p = 4, h=10, n=J, hide=T)
bin.avg <- as_tibble(rd_quartic$vars_bins)
quartic <- as_tibble(rd_quartic$vars_poly)

figure2 <- bin.avg %>%
  ggplot() +
  geom_point(aes(x=rdplot_mean_x,y=rdplot_mean_y)) + theme_bw() +
  geom_line(mapping=aes(x=rdplot_x,y=rdplot_y),data=linear,linetype='dashed') +
  geom_line(mapping=aes(x=rdplot_x,y=rdplot_y),data=quartic) +
  xlab("Monthly Premium - LIS Subsidy, 2006") +
  ylab("Log Enrollment Share, 2006")

J = 30
df_q3_30 <- df %>%
  filter(benefit == 'B',
         year==2006,
         LIS <= 10, LIS >=-10)

rd_linear <- rdplot(y = df_q3_30$log_share,
                    x = df_q3_30$LIS,
                    h = 4, p=1, hide=T)
linear <- as_tibble(rd_linear$vars_poly)

rd_quartic <- rdplot(y = df_q3_30$log_share,
                     x = df_q3_30$LIS,
                     c = 0, p = 4, h=10, n=J, hide=T)
bin.avg <- as_tibble(rd_quartic$vars_bins)
quartic <- as_tibble(rd_quartic$vars_poly)

figure3 <- bin.avg %>%
  ggplot() +
  geom_point(aes(x=rdplot_mean_x,y=rdplot_mean_y)) + theme_bw() +
  geom_line(mapping=aes(x=rdplot_x,y=rdplot_y),data=linear,linetype='dashed') +
  geom_line(mapping=aes(x=rdplot_x,y=rdplot_y),data=quartic) +
  xlab("Monthly Premium - LIS Subsidy, 2006") +
  ylab("Log Enrollment Share, 2006")
```
```{r Q3-display, tidy=TRUE, echo=FALSE, cache=TRUE, comment=NA, warning=FALSE}
figure2
figure3
```

4. With the notation above, @calonico2015 derive the optimal number of partitions for an evenly-spaced (ES) RD plot. They show that $$J_{ES,-,n} = \left\lceil \frac{V_{-}}{\mathcal{V}_{ES,-}} \frac{n}{\text{log}(n)^{2}} \right\rceil$$ and $$J_{ES,+,n} = \left\lceil \frac{V_{+}}{\mathcal{V}_{ES,+}} \frac{n}{\text{log}(n)^{2}} \right\rceil,$$ where $V_{-}$ and $V_{+}$ denote the sample variance of the subsamples to the left and right of the cutoff and $\mathcal{V}_{ES,.}$ is an integrated variance term derived in the paper. Use the `rdrobust` package in `R` (or `Stata` or `Python`) to find the optimal number of bins with an evenly-spaced binning strategy. Report this bin count and recreate your binned scatterplots from parts 2 and 3 based on the optimal bin number.


```{r Q4, tidy=TRUE, echo=TRUE, cache=TRUE, comment=NA, warning=FALSE,include=FALSE}
df_q4 <- df %>%
  filter(benefit == 'B',
         year==2006,
         LIS <= 10, LIS >=-10)

rd_linear <- rdplot(y = df_q4$log_share,
                    x = df_q4$LIS,
                    h = 4, p=1, hide=T)
linear <- as_tibble(rd_linear$vars_poly)

rd_quartic <- rdplot(y = df_q4$log_share,
                     x = df_q4$LIS,
                     c = 0, p = 4, h=10, hide=T,
                     binselect = 'esmv')
bin.avg <- as_tibble(rd_quartic$vars_bins)
quartic <- as_tibble(rd_quartic$vars_poly)

J <- rd_quartic$J

figure4 <- bin.avg %>%
  ggplot() +
  geom_point(aes(x=rdplot_mean_x,y=rdplot_mean_y)) + theme_bw() +
  geom_line(mapping=aes(x=rdplot_x,y=rdplot_y),data=linear,linetype='dashed') +
  geom_line(mapping=aes(x=rdplot_x,y=rdplot_y),data=quartic) +
  xlab("Monthly Premium - LIS Subsidy, 2006") +
  ylab("Log Enrollment Share, 2006")

```
```{r Q4-disply, tidy=TRUE, echo=FALSE, cache=TRUE, comment=NA, warning=FALSE}
print(paste0("Optimal bin number is: ", J))
figure4
```


5. One key underlying assumption for RD design is that agents cannot precisely manipulate the running variable. While "precisely" is not very scientific, we can at least test for whether there appears to be a discrete jump in the running variable around the threshold. Evidence of such a jump may suggest that manipulation is present. Provide the results from the manipulation tests described in @cattaneo2018. This test can be implemented with the `rddensity` package in `R`, `Stata`, or `Python`.

```{r Q5, tidy=TRUE, echo=TRUE, cache=TRUE, comment=NA, warning=FALSE,include=FALSE}
df_q5 <- df %>%
  filter(benefit == 'B',
         year==2006,
         LIS <= 10, LIS >=-10)

res <- rddensity(X = df_q5$LIS)
figure5 <- rdplotdensity(rdd=res, X=df_q5$LIS,
                     plotRange = c(-10,10))
```
```{r Q5-display, tidy=TRUE, echo=FALSE, cache=TRUE, comment=NA, warning=FALSE}
figure5
```


6. Recreate Panels A and B of Table 3 in @ericson2014 using the same bandwidth of $4.00 but without any covariates.

``` {r Q6, tidy=TRUE, echo=TRUE, cache=TRUE, comment=NA, warning=FALSE,include=FALSE}
my_RD <- function(y_name,x_name,h,data,p=1,c=0) {
  data$y <- data %>% pull(y_name)
  data$x <- data %>% pull(x_name)
  data <- data %>% filter( (x < h) & (x > -h))
  data$left <- 1*(data$x <= 0)
  data$x_left <- data$left * data$x
  data$x_right <- (1-data$left) * data$x
  
  if (p==1) {
    ols <- lm(y~left + x_left + x_right,data=data)
  } else if (p==2) {
    data$x_left2 <- data$x_left^2
    data$x_right2 <- data$x_right^2
    ols <- lm(y~left + x_left + x_left2 + x_right + x_right2, data=data)
  }
  print("NEED TO CLUSTER THE ERROR!!")
  return(ols)
}

RDwindow2006 <- df %>%
  filter(year==2006,
         LIS <= 4,
         LIS >= -4,
         benefit=='B') %>%
  select(uniqueID) %>% unlist()

df_temp <- df %>%
  filter(uniqueID %in% RDwindow2006) %>%
  group_by(uniqueID) %>%
  mutate(L1.LIS = lag(LIS, n=1, default=NA, order_by=year),
         L2.LIS = lag(LIS, n=2, default=NA, order_by=year),
         L3.LIS = lag(LIS, n=3, default=NA, order_by=year),
         L4.LIS = lag(LIS, n=4, default=NA, order_by=year)) %>%
  ungroup()

ols2006 <- my_RD('log_share','LIS',h=4,
                 data=df_temp%>%filter(year==2006),p=1,c=0)
ols2007 <- my_RD('log_share','L1.LIS',h=4,
                 data=df_temp%>%filter(year==2007),p=1,c=0)
ols2008 <- my_RD('log_share','L2.LIS',h=4,
                 data=df_temp%>%filter(year==2008),p=1,c=0)
ols2009 <- my_RD('log_share','L3.LIS',h=4,
                 data=df_temp%>%filter(year==2009),p=1,c=0)
ols2010 <- my_RD('log_share','L4.LIS',h=4,
                 data=df_temp%>%filter(year==2010),p=1,c=0)

panel1 <- msummary(list('2006'=ols2006, '2007'=ols2007, '2008'=ols2008,
                        '2009'=ols2009, '2010'=ols2010),
                   output = 'markdown',
                   vcov = ~orgParentCode,
                   coef_omit='(Intercept)',
                   coef_rename=c('left'='Below Benchmark, 2006',
                                 'x_left'='... Below Benchmark',
                                 'x_right'='... Above Benchmark'),
                   gof_map=c('nobs',
                             'r.squared'),
                   stars=c('*'=0.10,'**'=0.05,'***'=0.01))


ols2006 <- my_RD('log_share','LIS',h=4,
                 data=df_temp%>%filter(year==2006),p=2,c=0)
ols2007 <- my_RD('log_share','L1.LIS',h=4,
                 data=df_temp%>%filter(year==2007),p=2,c=0)
ols2008 <- my_RD('log_share','L2.LIS',h=4,
                 data=df_temp%>%filter(year==2008),p=2,c=0)
ols2009 <- my_RD('log_share','L3.LIS',h=4,
                 data=df_temp%>%filter(year==2009),p=2,c=0)
ols2010 <- my_RD('log_share','L4.LIS',h=4,
                 data=df_temp%>%filter(year==2010),p=2,c=0)
panel2 <- msummary(list('2006'=ols2006, '2007'=ols2007, '2008'=ols2008,
                        '2009'=ols2009, '2010'=ols2010),
                   output = 'markdown',
                   vcov = ~orgParentCode,
                   coef_map=c('left'='Below Benchmark, 2006'),
                   gof_map=c('nobs',
                             'r.squared'),
                   stars=c('*'=0.10,'**'=0.05,'***'=0.01))

```
```{r Q6-display, tidy=TRUE, echo=FALSE, cache=TRUE, comment=NA, warning=FALSE}
panel1
panel2
```

7. @calonico2020 show that pre-existing optimal bandwidth calculations (such as those used in @ericson2014) are invalid for appropriate inference. They propose an alternative method to derive minimal coverage error (CE)-optimal bandwidths. Re-estimate your RD results using the CE-optimal bandwidth (`rdrobust` will do this for you) and compare the bandwidth and RD estimates to that in Table 3 of @ericson2014.

```{r cs, tidy=TRUE, echo=TRUE, cache=TRUE, comment=NA, warning=FALSE,include=FALSE}


```
```{r cs-display, tidy=TRUE, echo=FALSE, cache=TRUE, comment=NA, warning=FALSE}

```

8. Now let's extend the analysis in Section V of @ericson2014 using IV. Use the presence of Part D low-income subsidy as an IV for market share to examine the effect of market share in 2006 on future premium changes. 


```{r Aux-func-RR, tidy=TRUE, echo=TRUE, cache=TRUE, comment=NA, include=FALSE, warning=FALSE}

```


```{r honest-display, tidy=TRUE, echo=FALSE, cache=TRUE, comment=NA, warning=FALSE}

```



9. Discuss your findings and compare results from different binwidths and bandwidths. Compare your results in part 8 to the invest-then-harvest estimates from Table 4 in @ericson2014.

Answers: 

10. Reflect on this assignment. What did you find most challenging? What did you find most surprising? 

Answers: 